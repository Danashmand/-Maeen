from flask import Flask, request, jsonify, session
import os
from ibm_watsonx_ai.foundation_models import Model
from ibm_watsonx_ai.client import APIClient
from sentence_transformers import SentenceTransformer
import gzip
import json
import chromadb
import random
import string

app = Flask(__name__)
app.secret_key = '22'  # Replace with a more secure key

# Function to retrieve credentials
def get_credentials():
    return {
        "url": "https://eu-de.ml.cloud.ibm.com",
        "apikey": "3Ls5_sdF4uZz00i6ZdHGZB1YBxRDfVgcUgkq11tZvjlB"
    }

# Get project_id and space_id from environment variables
project_id = "da2e1438-1e80-4b85-9c22-7565678d1498"
space_id = os.getenv("SPACE_ID")

# Initialize Watson API client
wml_credentials = get_credentials()
client = APIClient(wml_credentials=wml_credentials)
client.set.default_project(project_id)

# Initialize the sentence transformer model
emb = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

# Your vector index id and hydration of ChromaDB...
vector_index_id = "3c606a27-142c-4b67-8bbd-73501ee27d02"
vector_index_details = client.data_assets.get_details(vector_index_id)
vector_index_properties = vector_index_details["entity"]["vector_index"]

# Initialize the LLM model (Allam)
model_id = "sdaia/allam-1-13b-instruct"

parameters = {
    "decoding_method": "greedy",
    "max_new_tokens": 900,
    "repetition_penalty": 1
}

model = Model(
    model_id=model_id,
    params=parameters,
    credentials=get_credentials(),
    project_id=project_id,
    space_id=space_id 
)

# Hydrate ChromaDB with your knowledge base vectors
def hydrate_chromadb():
    data = client.data_assets.get_content(vector_index_id)
    content = gzip.decompress(data)
    stringified_vectors = str(content, "utf-8")
    vectors = json.loads(stringified_vectors)

    chroma_client = chromadb.Client()

    collection_name = "my_collection"
    try:
        collection = chroma_client.delete_collection(name=collection_name)
    except:
        print("Collection didn't exist - nothing to do.")
    collection = chroma_client.create_collection(name=collection_name)

    vector_embeddings = []
    vector_documents = []
    vector_metadatas = []
    vector_ids = []

    for vector in vectors:
        vector_embeddings.append(vector["embedding"])
        vector_documents.append(vector["content"])
        metadata = vector["metadata"]
        lines = metadata["loc"]["lines"]
        clean_metadata = {}
        clean_metadata["asset_id"] = metadata["asset_id"]
        clean_metadata["asset_name"] = metadata["asset_name"]
        clean_metadata["url"] = metadata["url"]
        clean_metadata["from"] = lines["from"]
        clean_metadata["to"] = lines["to"]
        vector_metadatas.append(clean_metadata)
        asset_id = vector["metadata"]["asset_id"]
        random_string = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10))
        id = "{}:{}-{}-{}".format(asset_id, lines["from"], lines["to"], random_string)
        vector_ids.append(id)

    collection.add(
        embeddings=vector_embeddings,
        documents=vector_documents,
        metadatas=vector_metadatas,
        ids=vector_ids
    )
    return collection

chroma_collection = hydrate_chromadb()

# Function to perform proximity search using the question
def proximity_search(question):
    # Encode the question to get its embedding
    query_vectors = emb.encode([question])  # Get embeddings as a NumPy array
    
    # Convert the NumPy array to a list
    query_vectors = query_vectors.tolist()

    # Perform the query in ChromaDB using the generated embedding
    query_result = chroma_collection.query(
        query_embeddings=query_vectors,
        n_results=vector_index_properties["settings"]["top_k"],
        include=["documents", "metadatas", "distances"]
    )

    # Reverse and return the documents from the query results
    documents = list(reversed(query_result["documents"][0]))

    return "\n".join(documents)

# Define the role instruction (this can be part of the prompt in each interaction)
ROLE_INSTRUCTION = '''ğŸŒŸ **Ø§Ù„Ø³ÙŠØ§Ù‚**: ÙŠØªÙ…Ø«Ù„ Ø¯ÙˆØ±Ùƒ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù„Ù†Ù…ÙˆØ°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¨Ø¥Ø¬Ø§Ø¨Ø§Øª ÙˆØ§Ø¶Ø­Ø© ÙˆØ³Ù‡Ù„Ø© Ø§Ù„ÙÙ‡Ù… Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø±Ø¯ÙˆØ¯ **Ø¹Ø±ÙŠØ¶Ø© Ø¬Ø¯Ø§Ù‹** Ù„Ù„ØªØ£ÙƒÙŠØ¯ØŒ ÙˆØ£Ù† ØªÙƒÙˆÙ† Ù…Ù†Ø³Ù‚Ø© ÙˆØ¬Ø°Ø§Ø¨Ø© Ø¨ØµØ±ÙŠØ§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ ÙˆØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù†Øµ Ù„ØªÙ…ÙŠÙŠØ² Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©.

**Ø§Ù„Ù‡Ø¯Ù**: Ø§Ù„Ù‡Ø¯Ù Ù‡Ùˆ Ø¶Ù…Ø§Ù† Ø£Ù† ÙŠÙÙ‚Ø¯Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¬Ø°Ø§Ø¨Ø©ØŒ ÙˆØ§Ø¶Ø­Ø©ØŒ ÙˆÙ…Ù†Ø¸Ù…Ø©. Ø§Ù„ØªØ±ÙƒÙŠØ² ÙŠÙƒÙˆÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø³Ø§Ø·Ø© ÙˆØªØ¹Ø²ÙŠØ² Ø§Ù„ÙˆØ¶ÙˆØ­ Ø¹Ø¨Ø± Ø¥Ø¨Ø±Ø§Ø² Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø¨Ù€**Ù†Øµ Ø¹Ø±ÙŠØ¶ Ø¬Ø¯Ø§Ù‹** ÙˆØ¥Ø¶Ø§ÙØ© Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ù„Ø¥Ø¶ÙØ§Ø¡ Ø·Ø§Ø¨Ø¹ ÙˆØ¯ÙˆØ¯.

**Ø§Ù„Ø£Ø³Ù„ÙˆØ¨**: ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ø±Ø¯ Ø¨Ø³ÙŠØ·Ø§Ù‹ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… **Ù†Øµ Ø¹Ø±ÙŠØ¶ Ø¬Ø¯Ø§Ù‹** Ø£Ùˆ Ù†Øµ Ø£ÙƒØ¨Ø± Ù„ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù‡Ù…Ø©. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¥Ù„Ù‰ ÙÙ‚Ø±Ø§Øª Ù‚ØµÙŠØ±Ø© Ø£Ùˆ Ù†Ù‚Ø§Ø· Ù„ØªØ¹Ø²ÙŠØ² Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©. ÙŠØ¬Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ø¨Ø´ÙƒÙ„ ÙŠØ¶ÙÙŠ Ø·Ø§Ø¨Ø¹Ø§Ù‹ Ø¯Ø§ÙØ¦Ø§Ù‹ ÙˆØ´Ø®ØµÙŠØ© Ù„Ù„Ø±Ø¯ Ø¯ÙˆÙ† Ù…Ø¨Ø§Ù„ØºØ©.

**Ø§Ù„Ù†Ø¨Ø±Ø©**: Ø§Ù„Ù†Ø¨Ø±Ø© ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† ÙˆØ¯-friendlyØŒ Ù…Ø³Ø§Ø¹Ø¯Ø©ØŒ ÙˆÙ…Ù‡Ù†ÙŠØ©ØŒ Ù…Ø¹ Ø£Ø³Ù„ÙˆØ¨ Ø³Ù‡Ù„ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„ÙŠÙ‡. ÙŠØ¬Ø¨ Ø£Ù† ØªØ´Ø¬Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©.

**Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù**: ÙŠØ³ØªÙ‡Ø¯Ù Ø§Ù„Ù…ØªØ­Ø¯Ø«ÙŠÙ† Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø°ÙŠÙ† ÙŠÙØ¶Ù„ÙˆÙ† Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙˆØ¬Ø²Ø©ØŒ Ù…Ù†Ø³Ù‚Ø© Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯ØŒ ÙˆØ¬Ø°Ø§Ø¨Ø© Ø¨ØµØ±ÙŠØ§Ù‹ØŒ Ù…Ø«Ù„ Ø§Ù„Ø·Ù„Ø§Ø¨ØŒ Ø§Ù„Ù…Ù‡Ù†ÙŠÙŠÙ†ØŒ Ø£Ùˆ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø¹Ø§Ø¯ÙŠÙŠÙ† Ø§Ù„Ø°ÙŠÙ† ÙŠØ¨Ø­Ø«ÙˆÙ† Ø¹Ù† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ù…Ø®ØªÙ„ÙØ©.

**Ø¥Ø±Ø´Ø§Ø¯Ø§Øª Ø§Ù„Ø±Ø¯**:
- Ø§Ø³ØªØ®Ø¯Ù… **Ù†ØµØ§Ù‹ Ø¹Ø±ÙŠØ¶Ø§Ù‹ Ø¬Ø¯Ø§Ù‹** Ù„Ù„ØªØ£ÙƒÙŠØ¯.
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ù„Ø¥Ø¶ÙØ§Ø¡ Ø§Ù„Ø¯ÙØ¡ (Ù…Ø«Ù„ ğŸ˜ŠğŸ‘).
- Ù‚Ù… Ø¨ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ ÙÙ‚Ø±Ø§Øª Ù‚ØµÙŠØ±Ø© Ø£Ùˆ Ù†Ù‚Ø§Ø· Ù…Ø±Ù‚Ù…Ø© Ù„Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©.
- Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ù†Ø¨Ø±Ø© ÙˆØ§Ø¶Ø­Ø©ØŒ Ù…Ø¨Ø§Ø´Ø±Ø©ØŒ ÙˆØ³Ù‡Ù„Ø© Ø§Ù„ÙÙ‡Ù….'''




def build_conversation_history(history, new_question, proximity_context):
    # Start the conversation with the role definition
    conversation = f"<s> [INST] {ROLE_INSTRUCTION} [/INST]\n"
    
    # Add the proximity context from the knowledge base at the top
    if proximity_context:
        conversation += f"{proximity_context}\n"
    
    # Append previous conversation turns (limit to recent ones)
    for turn in history:
        conversation += f"<s> [INST] {turn['question']} [/INST]\n{turn['response']}\n"
    
    # Add the new question at the end
    conversation += f"<s> [INST] {new_question} [/INST]"
    
    return conversation




MAX_HISTORY_TURNS = 3  # Only store the last 3 turns

@app.route('/ask', methods=['POST'])
def ask_question():
    data = request.json
    question = data.get("question", "")
    
    if not question:
        return jsonify({"error": "No question provided"}), 400

    # Initialize or retrieve conversation history
    conversation_history = session.get("conversation_history", [])

    try:
        # Perform proximity search or context retrieval
        proximity_context = proximity_search(question)
        print(proximity_context)
        # Build the conversation history with the new question
        prompt = build_conversation_history(conversation_history, question, proximity_context)
        
        # Generate the response from the model
        generated_response = model.generate_text(prompt=prompt)
        
        # Append the new turn (question and response)
        conversation_history.append({
            "question": question,
            "response": generated_response
        })

        # Keep only the last MAX_HISTORY_TURNS turns
        if len(conversation_history) > MAX_HISTORY_TURNS:
            conversation_history = conversation_history[-MAX_HISTORY_TURNS:]

        # Save the updated conversation history
        session["conversation_history"] = conversation_history
        
        return jsonify({"AI": generated_response})
    except Exception as e:
        return jsonify({"error": str(e)}), 500
    

@app.route('/reset', methods=['POST'])
def reset_conversation():
    # Clear the conversation history from the session
    session["conversation_history"] = []
    return jsonify({"message": "Conversation history reset successfully."})

# New GET route that returns "Hello, World!"
@app.route('/hello', methods=['GET'])
def hello_world():
    return jsonify({"message": "Hello, World!"})

if __name__ == '__main__':
    app.run(debug=True, port=5000)
